%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% PIPELINE DESIGN
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Pipeline Design}
\label{pipeline-design}
%
% pipeline enhancement, telemetry, parallelism
POLAR is a tuple routing approach designed for non-invasive integration into common database systems with support for operator pipelining. In contrast to other adaptive operator re-ordering approaches, POLAR pipelines do not require fine-grained intertwining of existing optimizers and runtime systems. As shown in Figure~\ref{fig:pipeline_design} (right), we enhance amenable pipelines with additional join orders. At runtime, we measure the performance of these orders and route tuples to well-performing orders while exploring others using an exploration budget. This section describes the compilation and execution of POLAR pipelines and related essential primitives.

\subsection{POLAR Pipeline Compilation}
\label{pipeline-enhancement}

%overview 
During query compilation (cf. Figure~\ref{fig:pipeline_design}), we replace amenable operator pipelines with POLAR pipelines. A POLAR pipeline contains alternative join orders and two dedicated operators: a \textit{multiplexer} (for tuple routing) and an \textit{adaptive union} $\cup$ (for result consolidation). In the following, we describe the pipeline selection, the dedicated operators, and the pipeline transformation in more detail.

\textbf{Pipeline Selection:} After query optimization and generation of a query execution plan---consisting of multiple operator pipelines---POLAR aims to replace all pipelines of left-deep join trees with at least two joins (where the right-hand-sides are build sides, and left-hand-side intermediates are probed in a pipelined fashion). The pipeline's source is the left-most node and fixed as POLAR's source of input tuples for the tuple routing. Our approach generates alternative join orders using a join order selection algorithm (cf. Section~\ref{sec:paths}) and includes them with the original join order in the POLAR pipeline. Although the approach of focusing only on existing join pipelines is limiting, it allows for a system integration without changing the query optimizer and robust performance that is at least as good as the original plan.

\textbf{Custom Operators:} Additionally, we introduce two new operators into each POLAR pipeline for tuple routing. The \emph{multiplexer} accepts sets of tuples from the source table and determines the next path and the number of tuples to route to that path. It uses performance indicators from previous path runs to make routing decisions. We explain the multiplexing logic in-depth in Section \ref{sec:routing_strategies}. After each path run, a lightweight \emph{adaptive union} operator processes the results from the last join. Besides normal union-all semantics, this operator re-arranges the additional columns from the joins to a consistent order of the original plan for all join paths.

\begin{figure}[!t]
    \centering
    \includegraphics[width=0.6\linewidth]{figures/join_order_search_space.pdf}
    \vspace{-0.15cm}
    \caption{The Join Order Search Space as a Tree: A path from root to leaf denotes a sequence of joins. The visited nodes are marked in green, and the digits indicate the order in which they are visited using the Next-Best Join Order Search. At step 8, the algorithm emits the first join order $\langle R, S, T, U \rangle$.}
    \label{fig:search_space}
    \vspace{-0.3cm}
\end{figure}

\textbf{Pipeline Transformation:} Finally, we replace the existing operator pipeline with a POLAR pipeline consisting of the multiplexer, the set of join orders, and the adaptive union. Note that the individual join orders reuse the read-only hash tables of the build sides without redundant allocation. This transformation does not break the pipeline to prevent further materialization points and redundant multiplexing overhead. Other non-blocking operators (\eg projections, filters) and the pipeline sink (\eg an aggregation) also remain unchanged. The POLAR pipeline allocates space for state per alternative join order (e.g., operator caches, intermediate result vectors) instead of once. However, this space overhead is negligible since we limit the number of join orders for large queries.

\begin{algorithm}[!t]
\caption{Next-best Join Order Search}\label{alg:enumeration}
\begin{algorithmic}[1]
\Require{Joins $J$, Edge Counts $n_0, ..., n_{\card{J}} \in N$, Max Join Orders $\mathit{MAX}$}
\Ensure{Join Orders $T$}
\State $R \gets \emptyset$
\State $S \gets \textsc{LegalJoinCandidates}(R, J)$ \Comment{Find first join candidates}
\For{$i \gets 0$ \textbf{to} $n_0$}
    \Comment{Consider $n_0$ of the candidates}
    \State $s_i \gets \textsc{GetNextJoin}(S)$
    \State $\mathit{prio} \gets (\card{R}, i)$
    \State $pqueue.\textsc{Enqueue}(prio, R, s_i)$
    \State $S \gets S \setminus s_i$
\EndFor
\While{$!pqueue.\textsc{Empty}()$ and $\card{J} < \mathit{MAX}$}
    \State $R, s \gets pqueue.\textsc{Dequeue}()$ \Comment{Remove next item}
    \State $R \gets R \oplus s$
    \If{$\card{R} = \card{J} - 1$}
        \State $R \gets R \oplus J \setminus R$ \Comment{Append remaining join}
        \State $T \gets T \cup R$
    \Else
        \State $S \gets \textsc{LegalJoinCandidates}(R, J)$
        \For{$i \gets 0$ \textbf{to} $n_{\card{R}}$}
            \State $s_i \gets \textsc{GetNextJoin}(S)$
            \State $\mathit{prio} \gets (\card{R}, i)$
            \State $pqueue.\textsc{Enqueue}(prio, R, s_i)$
            \State $S \gets S \setminus s_i$
        \EndFor
    \EndIf
\EndWhile
\State \Return $T \cup \textsc{GetOriginalJoinOrder}()$
\end{algorithmic}
\end{algorithm}


\subsection{Join Order Selection}
\label{sec:paths}

When generating alternative join orders for individual pipelines, we aim to compose a diverse set of orders that could handle a wide range of mis-estimated cardinalities and cluster data. The selection strategy should be robust for very large pipelines (\ie find good plans early) and should not need to re-invoke the query optimizer~(\ie ensure non-invasive integration and low compilation overhead). To this end, we propose a set of simple join order selection strategies that only leverage previously estimated cardinalities. 

\textbf{Next-best Search:} Algorithm~\ref{alg:enumeration} shows our \emph{next-best search}. It uses a priority queue to explore join candidates, similar to a breadth-first search. The algorithm considers the search space a tree with nodes representing legal join sequences, while their children represent potential join candidates. In this tree, the set of all paths from root to leaf node represents the set of all legal join orders. Figure~\ref{fig:search_space} shows an example of such a join order search tree. We explore the tree by retrieving all possible join candidates $S$ for a given node representing a partial join sequence $R$. The function $\textsc{GetNextJoin(S)}$ then determines the $n_{\card{R}}$ fittest candidates, with $n_{\card{R}}$ being the number of edges to consider at a certain tree level. For each candidate $s_i$, the algorithm pushes an item containing the current node, the join candidate $s_i$, the tree level (\ie the length of the current join sequence $R$), and the fitness index $i$. The priority queue compares its items based on the tree level and fitness index---similar to recent heuristic search strategies in join enumeration to maximize pruning \cite{HaffnerD23}---so that the fittest join candidate in the lowest level is always the next item to retrieve. 
Depending on the values for $N=(n_0, \ldots, n_{\card{J}})$, the maximum number of join orders to generate $\textit{MAX}$, and the implementation of $\textsc{GetNextJoin}$, the algorithm allows finding different join order subsets. For example, setting $N$ to increasing values favors diversity of join candidate options for the rear joins of a join order, whereas decreasing values do the opposite. To keep the pipeline's space and exploration overhead manageable, we set $\mathit{MAX}$ to 24, which is high enough to exhaustively enumerate all join orders with five relations for clique queries (in general, $(n-1)!$, and thus, $(5-1)!=24$) and six relations for chain queries (in general, $2^{n-2}$, and thus, $2^{6-2}=16$)~\cite{MoerkotteN06}.
We implement three versions of the $\textsc{GetNextJoin}$ function:
\begin{itemize}
\item \textbf{S1 \textsc{GetRandom}:} Pick a random join candidate.
\item \textbf{S2 \textsc{GetMinCard}:} Pick the join candidate with the lowest estimated cardinality.
\item \textbf{S3 \textsc{GetMinCardUc}:} Pick the join candidate with the lowest, uncertainty-adjusted cardinality (every join has an uncertainty level derived from the number of preceding operators, assuming that the number of operators is correlated with potential misestimations, we multiply each candidate's cardinality estimate by its uncertainty level).
\end{itemize}

\textbf{Basic Heuristics}
Besides the search-based approach, we use two simple additional heuristics to generate alternative join orders: 
\begin{itemize}
\item \textbf{S4 \textsc{PushDown}:} Permute the original join order such that each join gets pushed to be the first in the join order once if legal (assuming that the first join in the pipeline often has the largest performance impact~\cite{DBLP:conf/damon/SchubertGZM23}).
\item \textbf{S5 \textsc{PullUp}:} Pull each join to the last position in the join order if possible (assuming that join blowups may be mitigated if the problematic join is pulled up to the end of the join order as other joins may filter its input).
\end{itemize}
We introduced these different join order selection strategies to allow for a systematic experimental evaluation, but by default, we employ \textsc{GetMinCard}, which provides robust characteristics in our experiments. Moreover, we set $N$ to be $\textsc{Min}(4 - \card{R}, 2)$ to favor diversity for the first few join options in the set of join orders.

\subsection{Pipeline Execution}\label{sec:execution}

During query execution, POLAR routes tuples from the source table of a pipeline through multiple join paths. The pipeline executor of these paths reports the performance and calculates their \emph{resistance} for future routing decisions. By using thread-local state (e.g., for tuple buffers and multiplexer state), POLAR can execute its pipelines in parallel without blocking. In this section, we discuss the related techniques for pipeline orchestration, our resistance metric, and parallel execution strategies in detail.

\textbf{Pipeline Orchestration:} To process a POLAR pipeline, the host database system spawns a custom POLAR pipeline executor responsible for passing tuples to the operators with respect to the multiplexer's routing decisions. 
The executor fetches chunks (\ie mini-batches or sets of tuples) from the source table and passes them sequentially through the pipeline. The multiplexer consumes a chunk and returns an output chunk containing a subset of the input (or the whole input) and the index of the next join order to pass the subset to. If the multiplexer does not return all tuples from the input, the executor re-invokes the multiplexer with the same input chunk in the next iteration to emit the next tuple subset instead of fetching a new chunk from the source. After routing the chunk to its dedicated join order, the executor passes the chunk to the adaptive union, other operators in the pipeline, and finally to the pipeline sink.
During this process, we count the number of intermediates appearing within the path as a performance indicator. We chose intermediate counts over clock time or CPU cycles because they allow an isolated observation of a single iteration (irrespective of other operators and parallelism), and the related $C_{out}$ cost model is known to be simple yet very accurate \cite{moerkotte23, LeisGMBK015}. Moreover, a clock time metric is biased towards paths receiving many input tuples as their throughput tends to be higher due to vectorization. After fully processing one multiplexer output chunk in a join order, the executor reports back the number of intermediates from that routing iteration to the multiplexer. This design allows adapting the \emph{plans of least resistance} to cluster data. For this reason, we currently never discard any of the join orders.

\textbf{Resistance Metric:} As a proxy for performance, the POLAR executor calculates a join order \emph{resistance}. This quantity comprises the sum of intermediate results $I$ observed in the current routing iteration, the number of tuples routed to the current join order $T$, and a constant $w$ representing the overhead of a routing iteration without intermediate results. We calculate the resistance $r$ as ${r = \frac{I}{T} + w}$. The overhead constant $w$ prevents edge cases of a routing iteration with zero intermediates per input counting as infinitely better than an iteration with one intermediate because there are still probing costs. If only a few tuples are routed to a join order, the resistance may not be representative for a larger set of tuples. Consequently, the executor applies a moving average from previous iterations for smoothing fluctuations.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{figures/parallel-exec.pdf}
    \vspace{-0.5cm}
    \caption{Parallel Execution: Each thread processes a pipeline with an isolated state, sharing build sides to probe into.}
    \vspace{-0.25cm}
    \label{fig:parallel-exec}
\end{figure}

\textbf{Parallel Execution:} Similar to traditional data-parallel processing, POLAR executes pipelines in a multi-threaded fashion by starting multiple executors with thread-local states (cf. Figure~\ref{fig:parallel-exec}). The executors concurrently fetch batches of tuples from the pipeline source and push results to the sink. Each executor has an isolated multiplexer state and calculates the path resistances solely based on the tuples it has fetched. Note that the executors only isolate their processing states but share build-side data structures such as read-only hash tables. With the input tuples, the executor follows the paths sequentially and independently from each other. The lack of a global multiplexer state may delay routing decisions to better paths as each multiplexer must individually measure resistances before finding the next path. On the other hand, this parallel execution method avoids synchronization among the executors preventing wait time. As an alternative model for parallel processing to compare against, POLAR supports spawning one thread per join order and applying a backpressure mechanism to route tuples in a self-scheduling manner (cf. Section~\ref{sec:backpressure}).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% ROUTING STRATEGY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Routing Strategies}
\label{sec:routing_strategies}

At the core of POLAR pipelines is the multiplexer operator that makes routing decisions to determine the number of input tuples for each join order. To this end, the pipeline executor passes an input chunk (by default 1024 tuples) to the multiplexer, which uses a \emph{routing strategy} to return the next join path index and a subset of the tuples to route. The routing strategies attempt to follow the \emph{plans of least resistance}, which is the---potentially temporally changing---sequence of join order paths that incur the fewest number of intermediates. In this section, we first discuss the overall multiplexer algorithm, followed by four dedicated routing strategies used by the multiplexer and one self-scheduling strategy.

%%%%%%%
\subsection{Overall Multiplexer Algorithm}

Algorithm \ref{alg:multiplexer} shows the overall multiplexer algorithm. In the initialization phase, the multiplexer sends a small number of tuples to each join order with a resistance of zero (\ie an uninitialized join order without reported resistance) to measure initial performance. When all join orders are initialized, the multiplexer requests a tuple distribution from a configurable routing strategy. The distribution indicates the fraction that each join order receives from the current input chunk. The algorithm finally returns the join order index with the largest fraction and its respective input tuple count. If the multiplexer does not emit all tuples from the input chunk, the multiplexer emits the remaining tuples from the tuple distribution in the next iteration until the input chunk is fully processed (cf. Section~\ref{sec:execution}).
%
In the following, we introduce four different routing strategies implementing the tuple distribution method. Assuming that POLAR is executed in a vectorized database system, the implementation must trade-off path optimality (following the cheapest path through the join orders) and operator cache friendliness (minimizing the number of join order switches). The caching aspect can impact the processing performance as the pipeline executor must flush all operator caches buffering intermediates for vectorization before reporting the join order resistance to ensure that each input tuple has been fully processed and was thus correctly counted. Additionally, processing without buffering or too frequent plan switches may increase the number of instruction cache misses~\cite{SirinTPA16}. 

\begin{algorithm}[!t]
\caption{Multiplexer}\label{alg:multiplexer}
\begin{algorithmic}[1]
\Require{Tuple Distribution $T$, Resistances $\mat{W}$}
\Ensure{Join Order Index $\mathit{idx}$, Tuple count $c$}
\If{$\exists t_{\mathit{idx}} \in T: t_{\mathit{idx}} > 0$}
    \State $\mathit{fraction} \gets t_{\mathit{idx}}$ \Comment{Route tuples from previous multiplexing}
    \State $t_{\mathit{idx}} \gets 0$
    \State\Return $\mathit{idx}$, $\mathit{fraction} \cdot \mathit{INPUT\_SIZE}$
\ElsIf{$\exists w_{\mathit{idx}} \in \mat{W}: w = 0$} \Comment{Initialize join order}
    \State\Return $\mathit{idx}$, $\textsc{INIT\_COUNT}$
\EndIf
\State $T \gets \textsc{GetTupleDistribution}(\mat{W})$
\State $\mathit{idx}, \mathit{fraction} \gets \textsc{max}(T)$
\State $t_{\mathit{idx}} \gets 0$
\State\Return $\mathit{idx}$, $\mathit{fraction} \cdot \textsc{INPUT\_SIZE}$
\end{algorithmic}
\end{algorithm}

%%%%%%%
\subsection{Static Selection}

Static routing strategies, or path selection approaches, do not perform any exploration apart from initialization. For this reason, they are very simple to implement, and thus, we omit their pseudo-code of $\textsc{GetTupleDistribution}$ but provide high-level descriptions.

\textbf{R1 \textsc{InitOnce}:} This simple strategy retrieves the join order with the lowest resistance after the initialization phase and then routes every following chunk to that join order. \textsc{InitOnce} is extremely cache-friendly (i.e., in terms of tuple buffering in operator pipelines) because it requires no cache flushes until the end of the query. However, this strategy is prone to bad routing decisions if a join order only performs well for the first few tuples. Moreover, it is unable to find well-performing paths for pipelines with different join orders being the best choice for different clusters of data.

\textbf{R2 \textsc{Opportunistic}:} The \textsc{Opportunistic} routing strategy is similar to \textsc{InitOnce} but makes use of the resistance reports after routing each chunk. If the reported resistance of the current join order exceeds the resistance of another, it routes the next input chunks to that join order. This approach allows switching join orders if the previous order deteriorates. However, the decision is solely based on the resistance of a single join order and old initialization results of others, which may miss additional opportunities, such as better plans for clusters of data. Cache flushing is needed but can be reduced by only updating the resistance after every $n$ chunks, trading granularity with cache-efficiency.  

%%%%%%%
\subsection{Pro-active Exploration}

In order to enable robust pathfinding for complex paths and varying data characteristics, routing strategies must pro-actively explore alternative join orders. To this end, these strategies periodically route tuples to join orders that performed sub-optimal in the past. We introduce two strategies that both use the notion of an \textit{exploration budget}. This budget bounds the overhead we allocate for finding the optimal join path with minimal intermediate results. The two following strategies use the exploration budget to calculate a tuple distribution over the join orders producing additional intermediate results within that overhead based on the join order resistances measured so far.

\begin{algorithm}[!t]
\caption{GetTupleDistribution -- \textsc{AdaptTupleCount}}\label{alg:adapt_tuple_count}
\begin{algorithmic}[1]
\Require{Resistances $\mat{W}$}
\Ensure{Tuple Distribution $T$}
\State $T \gets \textsc{Initialize}(\card{\mat{W}}, 1)$
\State $\mat{W} \gets \textsc{SortInc}(\mat{W})$
\State $\mathit{cost} \gets \textsc{LastElement}(\mat{W})$
\For{$i \gets \card{\mat{W}} - 1$ \textbf{to} $0$}\Comment{Calculate distribution bottom-up}
    \State $\mathit{target} \gets w_i \cdot (1 + \textsc{BUDGET})$
    \State $\mathit{decrease} \gets \frac{w_i - \mathit{target}}{w_i - \mathit{cost}}$
    \For{$j \gets i+1$ \textbf{to} $\card{\mat{W}}$}\Comment{Adjust fractions to new target}
        \State $t_j \gets t_j \cdot \mathit{decrease}$
    \EndFor
    \State $t_i \gets 1 - \mathit{decrease}$
    \State $\mathit{cost} \gets \mathit{target}$
\EndFor
\State\Return $T$
\end{algorithmic}
\end{algorithm}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/routing_example.pdf}
    \caption{Behavior of four different routing strategies on an example scenario of 30 batches of 10 tuples each (green: optimal join paths, blue diamond: multiplexer invocations, blue line: path chosen by routing strategy).}
    \label{fig:routing_example}
\end{figure*}

\textbf{R3 \textsc{AdaptTupleCount}:} The \textsc{AdaptTupleCount} strategy (Algorithm~\ref{alg:adapt_tuple_count}) adapts the tuple allocation for each input chunk according to the exploration budget. This strategy initializes the output tuple distribution with ones (line 1), orders paths by their measured resistances (line 2), and adjusts the distribution in a bottom-up fashion. We start by reducing the problem to the two join orders with the highest resistances. The target cost is based on the lower resistance and the exploration budget, which we then use to calculate a \textit{decrease} factor (line 6). By multiplying that factor with the join order's tuple fraction (which was initialized to one), we find the amount of tuples that must be sent to the worst join order to stay within the exploration budget, based on the resistance of the second-last join order. Consequently, the amount for the second-last order is $1 - \mathit{decrease}$ (line 10). We calculate these values for the next-best join order while decreasing the fractions of the orders with higher resistances until we reach the first join order. \textsc{AdaptTupleCount} calculates tuple distributions for each incoming chunk, allowing for fine-grained path exploration bounded by the exploration budget. However, splitting each chunk into smaller sets of tuples obstructs vectorized execution and causes many cache flushes to report resistances. In our implementation, we only serve join orders receiving 64 or more input tuples to reduce the number of chunk splits. If a join order would receive less than 64 tuples, we redistribute those tuples to the other join orders. At the next multiplexer invocation, the implementation recalls those unserved tuples when calculating the next tuple distribution. 

\begin{algorithm}[!t]
\caption{GetTupleDistribution -- \textsc{AdaptWindowSize}}\label{alg:adapt_window_size}
\begin{algorithmic}[1]
\Require{Resistances $\mat{W}$}
\Ensure{Tuple Distribution $T$}
\State $T \gets \textsc{Initialize}(\card{\mat{W}}, 0)$
\State $t_{\textsc{minIndex}(W)} \gets 1$ \Comment{Route all tuples to least resistant order}
\State $\mathit{size}$, $\mathit{offset} \gets \textsc{GetWindowState}()$
\If{$\mathit{size} = 0$} \Comment{Determine window size}
    \State $W^{\prime} \gets \mat{W} \setminus \textsc{min}(\mat{W})$
    \State $\mathit{size} \gets \frac{1}{\textsc{INPUT\_SIZE}} \cdot \frac{\sum w^{\prime}_i \cdot \textsc{INIT\_COUNT}}{\textsc{BUDGET} \cdot \textsc{min}(W)}$
\EndIf
\If{$\mathit{offset} < \mathit{size}$}
    \State $\mathit{offset} \gets \mathit{offset} + 1$
\Else \Comment{Re-explore join orders next time}
    \State $\mat{W} \gets \textsc{SetToZero}(\mat{W} \setminus \textsc{min}(\mat{W}))$ \Comment{Reset resistances}
    \State $\mathit{offset}, \mathit{size} \gets 0$
\EndIf
\State $\textsc{SetWindowState}(\mathit{size}, \mathit{offset})$
\State\Return $T$
\end{algorithmic}
\end{algorithm}

\textbf{R4 \textsc{AdaptWindowSize}:} In contrast to \textsc{AdaptTupleCount}, the \textsc{AdaptWindowSize} strategy does not calculate individual tuple counts per join order. Instead, this strategy either routes complete chunks or a static, low number of tuples and adapts the window size (\ie number of input chunks) within which it will only serve the best join order. When exceeding the window, it re-initializes the remaining join orders by routing a small number of tuples to each of them. The internals of this strategy are shown in Algorithm~\ref{alg:adapt_window_size}, which distinguishes between three cases. Irrespective of the case, this strategy always returns a tuple distribution in which the best order receives the whole input chunk (line 2). If there is no window size calculated yet (line 4), we estimate the number of intermediates occurring in a reinitialization phase based on the resistances and adjust the number of tuples for reinitialization accordingly. We then divide the cost estimate by the overhead allowed by the exploration budget resulting in the number of tuples that should be routed to the best join order before reinitializing the others. The number of tuples per chunk scales this value down to the window size (line 6). If the current offset does not exceed the window size, we increment it (line~9). Finally, if the window size was exceeded, we set the resistances for all join orders---except the best---to zero (line 12) to trigger the initialization in the next multiplexer invocation. By routing multiple chunks to the same join order, the \textsc{AdaptWindowSize} strategy better allows for vectorization and can defer cache flushing until the window size is exceeded. On the other hand, its path exploration granularity is more coarse-grained than \textsc{AdaptTupleCount} as changes in resistances may appear within the routing window.

\begin{example2}[Routing Example] To illustrate the behavior of the four different routing strategies, Figure \ref{fig:routing_example} compares the multiplexer decisions for each of them in an example scenario. Given a POLAR pipeline with three join orders, 30 input chunks containing 10 tuples each. The resistances of the join orders change after every 10 chunks, namely $C_0 \gets \langle 1, 10, 15 \rangle$, $C_{10} \gets \langle 10, 15, 5 \rangle$, and $C_{20} \gets \langle 10, 1, 5 \rangle$. The resulting optimal path changes from the first to the third and then the second join order (indicated as green solid lines). The overlay blue diamonds show the multiplexer invocations of the different paths, and the blue line indicates the chosen path of least resistance. The \textsc{InitOnce} strategy tests every join order once in the beginning, then follows the optimal path temporarily but only until the 10th chunk. The \textsc{Opportunistic} strategy switches to the correct join order after the first one deteriorates but misses the second switch as it does not perceive the other join order's resistances. \textsc{AdaptTupleCount} correctly adapts to the optimal join paths but requires many switches and costly multiplexer invocations, including cache flushing. Finally, \textsc{AdaptWindowSize} first uses a large window so that it detects the join order switch only after a delay of a few chunks. Afterward, it reduces the window size as the difference between the resistances decreases. Therefore, the next switch comes after a shorter delay due to the finer granularity from the window resizing.
\end{example2}

\subsection{Self-scheduling}\label{sec:backpressure}

\textbf{R5 \textsc{Backpressure}:} To enable comparing against a self-scheduling strategy without parameters, we include a \enquote{backpressure} strategy. Instead of using a multiplexer, the POLAR pipeline spawns individual threads for each join order so that each thread concurrently pulls new input chunks. The approach does not depend on a budget and simply favors faster join orders as they can pull more chunks per time unit than others. The \textsc{Backpressure} strategy does not rely on multiplexing, does not require any operator cache flushes, and thus fully supports vectorized execution within each thread. However, with up to \textit{MAX} join orders (24 by default), this strategy has the intrinsic limitation that the majority of threads waste CPU cycles on sub-optimal join orders. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% LIMITATIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Limitations}
\label{sec:limits}
%
POLAR is designed for adaptive query processing with non-invasive system integration as well as small and bounded overhead. This design leads to certain limitations as its applicability is ultimately dependent on the system's existing query optimizer. 
\begin{itemize}
\item \emph{Amenable Pipelines:} POLAR only replaces left-deep-trees. If the optimizer emits a right-deep tree (where intermediates feed into the build side of hash joins), POLAR cannot generate alternative join orders, as there are no pipelines with more than one join. Support for directed acyclic graphs (DAGs) and bushy trees is interesting future work.
\item \emph{Source Table:} As POLAR replaces normal operator pipelines that consume tuples from a specific source, it cannot change the source (sometimes called driver \cite{LiSMBCL07}) table.
\item \emph{Join Orders:} Our join order selection strategies use---except for uncertainty heuristics---only existing optimizer statistics. Thus, the alternative join orders could lack a well-performing join order for pipelines with many joins.
\item \emph{Operator Types:} So far, we only support pipelines with sequences of joins. Extended support for additional operators---such as projection, selection, and groupjoin \cite{MoerkotteN11}---is interesting future work as well.
\end{itemize}
