# Frame input
data = read($1)

# Detect and apply schema
sc = detectSchema(data)
data = applySchema(data, sc)

# Transform encode
spec = read($2, data_type="scalar", value_type="string")
[Xt, M] = transformencode(target=data, spec=spec)

# Replace all Nan Values.
X = replace(target=Xt, pattern=NaN, replacement=0);

# Extract X and Y
Y = X[1:nrow(X),ncol(X)]
X = X[1:nrow(X), 1:(ncol(X)-1)]

# pre-process normalize
[X, cmin, cmax] = normalize(X)

# Train model
bias = lm(X=X, y=Y, reg = 1e-1, icpt = 2, tol=1e-10, verbose = TRUE)

# Validate model
y_predict_test = lmPredict(X = X, B=bias, ytest=Y, icpt = 2, verbose = TRUE)

stats = function(Matrix[Double] P, Matrix[Double] Y, Double split){
	print("Split: " + split)
	Pc = (P > split) + 1
	[nn, ca_test] = confusionMatrix(Pc, Y)
	accuracy = sum(Y == Pc) / nrow(Y)
	print("Accuracy:")
	print(accuracy)
	print("Confusion Matrix: ")
	print(toString(ca_test))
}
Y_c = Y +1
stats(y_predict_test, Y_c, 0.5)

# Read Test data
data2 = read($3)
data2 = applySchema(data2, sc[1:1,1:ncol(sc) -1])
M_t = M[1:nrow(M),1:ncol(M) -1]
# Transform Apply
Xt = transformapply(target=data2, spec=spec, meta=M)
[Xt, cmin, cmax] = normalize(Xt)
P = lmPredict(X=Xt, B=bias, icpt=2, verbose=FALSE)

## Post processing ... makes it worse
# P = normalize(P)
# P = 1 / (1+exp(-P)) # Sigmoid
# P = max(0, min(1,P))
# P = P < 0.5

# Construct output file.
Id = $4
y_file = cbind(seq(Id,Id + nrow(Xt)-1), P)
col_names = ["id", "target"]
y_file = as.frame(y_file, col_names)
# change the data types to make the saved frame the right type of csv
sc = frame("Tmp",rows=1,cols=2)
sc[1,1] = "INT32"
sc[1,2] = "FP64"
y_file = applySchema(y_file, sc) 
write(y_file, "tmp/" + $5, format="csv", header=TRUE)
