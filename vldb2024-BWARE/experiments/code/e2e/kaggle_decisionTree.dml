# Frame input
data = read($1)
# Detect and apply schema
M = nrow(data)
print(M)
sc = detectSchema(data)
data = applySchema(data, sc)

# Transform encode
spec = read($2, data_type="scalar", value_type="string")
[Xt, M] = transformencode(target=data, spec=spec)

# Replace all Nan Values.
X = replace(target=Xt, pattern=NaN, replacement=0);

# Extract X and Y
Y = X[1:nrow(X),ncol(X)] + 1
X = X[1:nrow(X), 1:(ncol(X)-1)]

# pre-process normalize
# [X, cmin, cmax] = normalize(X)  # No Normalization in decisionTree

# Train model
ctypes = matrix(1, rows= 1, cols=ncol(X) + 1)
ctypes[1,ncol(X)+1] = 2 # Categorical y

# print(toString(X))
Model = decisionTree(X=X, y=Y, ctypes=ctypes, seed=42, verbose = TRUE)

# Validate model
P = decisionTreePredict(X = X, M=Model, ctypes=ctypes, verbose = TRUE)

stats = function(Matrix[Double] P, Matrix[Double] Y, Double split){
	print("Split: " + split)
	# Pc = (P > split) + 1
	[nn, ca_test] = confusionMatrix(P, Y)
	accuracy = sum(Y == P) / nrow(Y)
	print("Accuracy:")
	print(accuracy)
	print("Confusion Matrix: ")
	print(toString(ca_test))
}

stats(P, Y, 0.5)

# Read Test data
data2 = read($3)
data2 = applySchema(data2, sc[1:1,1:ncol(sc) -1])
M_t = M[1:nrow(M),1:ncol(M) -1]
# Transform Apply
Xt = transformapply(target=data2, spec=spec, meta=M)
# [Xt, cmin, cmax] = normalize(Xt) # No Normalization in decisionTree
P = decisionTreePredict(X=Xt, M=Model, ctypes=ctypes, verbose = TRUE) -1

## Post processing ... makes it worse
# P = normalize(P)
# P = 1 / (1+exp(-P)) # Sigmoid
# P = max(0, min(1,P))
# P = P < 0.5

# Construct output file.
Id = $4
y_file = cbind(seq(Id,Id + nrow(Xt)-1), P)
col_names = ["id", "target"]
y_file = as.frame(y_file, col_names)
# change the data types to make the saved frame the right type of csv
sc = frame("Tmp",rows=1,cols=2)
sc[1,1] = "INT32"
sc[1,2] = "FP64"
y_file = applySchema(y_file, sc) 
write(y_file, "tmp/" + $5, format="csv", header=TRUE)
