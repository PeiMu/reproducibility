

# Frame input
data = read($1)

# Detect and apply schema
sc = detectSchema(data)
data = applySchema(data, sc)

print(toString(data[1:10,1:20]))

# Transform encode
spec = read($2, data_type="scalar", value_type="string")
[Xt, M] = transformencode(target=data, spec=spec)

# Replace all Nan Values.
X = replace(target=Xt, pattern=NaN, replacement=0);

# Extract X and Y Criteo
Y = X[1:nrow(X), 1]
X = X[1:nrow(X), 2:(ncol(X))]

# pre-process normalize
[X, cmin, cmax] = normalize(X)

# Train model
[C_n, Y_n] = kmeans(X=X, k=100, runs= 1, max_iter=30, eps= 1e-17, seed= 13, is_verbose=TRUE)

# Train stats
Y_n_2 = kmeansPredict(X=X, C=C_n)
# stats(p_train, Y, 0.5)

print(toString(Y_n_2, rows=min(nrow(Y_n_2), 20), cols=min(ncol(Y_n_2), 100)))

# Read Test data
data2 = read($3)

# Apply schema from training
data2 = applySchema(data2, sc)

# Transform Apply
X_test = transformapply(target=data2, spec=spec, meta=M)

# Replace all Nan Values.
X_test = replace(target=X_test, pattern=NaN, replacement=0);

# Extract X and Y Criteo
Y_test = X_test[1:nrow(X_test), 1]
X_test = X_test[1:nrow(X_test), 2:ncol(X_test)]

# normalize
X_test = normalizeApply(X_test, cmin, cmax)

# test Statistics
P_test = kmeansPredict(X=X_test, C=C_n)

print(toString(P_test, rows=min(nrow(P_test), 20), cols=min(ncol(P_test), 100)))